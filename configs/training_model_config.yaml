#Configuration of the base_trainer.py file
base_trainer.py:
  n_jobs: -1
  cv: 5
  verbose: 3
  n_iter: 10   # For RandomizerSearchCV

#Configuration of the classification.py file
classification.py:

  scoring: "accuracy"
  random_state: 42
  max_iter: 1000

  param_grid:
    LogisticRegression:
      C: [0.1, 1, 10]
      solver: ["liblinear", "lbfgs"]
    RandomForestClassifier:
      n_estimators: [100, 200, 300, 500]
      max_depth: [5, 10, 15]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
      max_features: ["sqrt", "log2", None]
      bootstrap: [True, False]
    LinearSVC:
      C: [0.01, 0.1, 1, 10, 100]
      max_iter: [1000, 5000, 10000]
      dual: [True, False]
    GaussianNB: 
      var_smoothing: [0.0000000010, 0.0000000100, 0.0000001000]        # [1e-9, 1e-8, 1e-7] Fix this error
    MultinomialNB:
      alpha: [0.1, 0.5, 1.0, 5.0, 10.0]
      fit_prior: [True, False]


#Configuration of the regression.py file
regression.py:

  scoring: "acuracy"
  random_state: 42
  max_iter: 1000

  param_grid:
    RandomForest:
      n_estimators: [100, 200, 300]
      max_depth: [10, 20, None]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
      max_features: ["sqrt", "log2", None]
      bootstrap: [True, False]
    LinearRegression: {} # Linear regression doesn't require optimization
    KNN:
      n_neighbors: [3, 5, 7, 9, 11]
      weights: ["uniform", "distance"]
      p: [1, 2]
      algorithm: ["auto", "ball_tree", "kd_tree", "brute"]
    LinearSVR:
      kernel: ["linear", "poly", "rbf"]
      C: [0.1, 1, 10, 100]
      epsilon: [0.01, 0.1, 0.2]
      gamma: ["scale", "auto"]

